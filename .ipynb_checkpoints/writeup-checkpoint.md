Our research explored how comments on a vegan creator’s TikTok video reflected broader perceptions of vegan and vegetarian diets. Using 1,000 comments, we aimed to sort reactions into two major categories: those that support plant-based eating and those that oppose it. Achieving reliable coding turned out to be the hardest part. Early on, our concepts were very vague (“for” vs. “against” veganism), which led to confusion, especially around edge-case topics like seafood. Once we rewrote the prompt specifying and incorporating indicators (explicit praise, adopting the diet, mocking, appeals to taste, etc.), both the AI and us aligned far better. This clarity boosted Krippendorff’s Alpha to 0.750 for Concept 1 and 0.619 for Concept 2, showing substantial improvement in inter-rater reliability.

The results reveal an interesting dynamic in how different viewpoints surface on social platforms. Comments supportive of veganism gathered more likes overall, which makes sense given the vegan creator’s audience. Yet opposing comments showed up more frequently in the “top” comment section. Our interpretation is that supportive comments may get buried in reply chains, while critical comments posted by outsiders stand alone and are therefore more visible. This also explains why opposing comments received the most replies: they tended to spark arguments and outrage from the creator’s supporters, driving up engagement.

Overall, the analysis shows that comment sections around vegan content are not simply divided into supporters and critics. Clearer concept definitions were essential for us (and the LLM) to code this complexity accurately, underscoring how important precise instructions are when analyzing messy, emotionally charged online discourse.